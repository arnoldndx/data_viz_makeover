---
title: "Assignment"
description: |
  My approach and solution to Mini Challenge 1 of the VAST Challenge 2021.
author:
  - name: Arnold Ng
    url: {}
date: 07-16-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,
                      tidy.opts=list(width.cutoff=40),
                      tidy=TRUE)
```

```{css, echo=FALSE}
#format table captions
caption {
  font-size: 20px;
  font-weight: bold;
}
```

```{r echo=FALSE}
#load relevant libraries
packages = c('DT','ggiraph','plotly','tidyverse',
             'tidytext','readtext','lubridate','formatR',
             'textstem', 'tm', 'slam')

for (p in packages){
  if(!require(p,character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}

#set working directory to reference data files
setwd("~/0. SMU MITB/9. ISSS608 Visual Analytics & Applications/arnoldndx/data_viz_makeover/_posts/2021-07-16-assignment")
```
# 1. Task

The task is to use visual analytics to examine text data comprising:

* news articles; 
* GAStech employee email headers;
* GAStech employee records; and
* GAStech employee resumes

in order to answer the following questions.

**QUESTION 1:** Characterize the news data sources provided. Which are primary sources and which are derivative sources? What are the relationships between the primary and derivative sources? Please limit your answer to 8 images and 300 words.

**QUESTION 2:** Characterize any biases you identify in these news sources, with respect to their representation of specific people, places, and events. Give examples. Please limit your answer to 6 images and 500 words.

**QUESTION 3:** Given the data sources provided, use visual analytics to identify potential official and unofficial relationships among GASTech, POK, the APA, and Government. Include both personal relationships and shared goals and objectives. Provide evidence for these relationships. Please limit your answer to 6 images and 400 words.

# 2. Data Preparation

Firstly, we will need to clean up and process the data into data tables to facilitate analysis. We will use a combination of R tools and manual inspection/editing to clean up the data.

There are three main datasets that will need to be processed and tidied up. The first set comprises the news articles. They will have to be collected into a data table for analysis, with key article details such as title, author, publish date, etc. extracted to facilitate analysis. The second set of data comprises the employee relationships to each other, as well as entities such as countries, organisations, persons outside GAStech, etc. The third and final set of data comprises email headers for two weeks worth of emails, along with labels of the type of emails. 

## 2.1. News Articles

There is noise in the news article data, which includes incosistent line breaks, inconsistent formatting of article details such as dates, author names, etc., and inconsistent details provided per article. This has to be taken into account in processing the article data.

### **Step 2.1.1:** Combine articles into single table for checking

We first begin by combining the article data into a single table to facilitate checks. We get the easy part out of the way and clean up the line breaks, by replacing all double line breaks with single line breaks with the code below.

```{r eval=FALSE}
articles <- readtext("MC 1/News Articles/*")

for (row in 1:nrow(articles)){
  #clean up the text of breaks
  while (str_detect(articles[row,'text'],'\n ')){
    articles[row,'text'] <- str_replace_all(articles[row,'text'],"\n ","\n")
  }
  while (str_detect(articles[row,'text'],'\n\n')){
    articles[row,'text'] <- str_replace_all(articles[row,'text'],"\n\n","\n")
  }
}
```

We then export the data for manual cleaning (i.e. edit the text directly in the csv file).

```{r eval=FALSE}
#export data for manual cleaning
write.csv(articles,"article_consol.csv")
```

### **Step 2.1.2:** Load cleaned data and convert to article data into analysable dataframe

We now begin the task of converting the data into an analysable format. 

First, we perform a first pass manual check of all the article text and manually clean up the data into a consistent format.Then we load in the cleaned data.

```{r}
#load in cleaned data
article_data <- read.csv("article_consol_edit.csv")
```

Next, we convert the article data into an analysable dataframe to with the relevant article information separated out. We also ensure that the published dates are properly formatted for analysis.

```{r, message = FALSE, warnings = FALSE}
#create dataframe to store article data
article_df <- data_frame(doc_id = rep('',nrow(article_data)),
                         source = rep('',nrow(article_data)),
                         title = rep('',nrow(article_data)),
                         author = rep('',nrow(article_data)),
                         location = rep('',nrow(article_data)),
                         published = rep('',nrow(article_data)),
                         text = rep('',nrow(article_data)))

#define the article details to be captured
headers <- c('source',
             'title',
             'author',
             'location',
             'published')

for (row in 1:nrow(article_data)){
  article_text <- str_split(article_data$text[row],'\n')
  article_df$doc_id[row] <- article_data$doc_id[row]
  for (i in 1:length(article_text[[1]])){
    detail <- str_trim(str_split_fixed(article_text[[1]][i],":",2))
    # check if any of the string headers corresponds to article details, otherwise treat as body text
    if (tolower(detail[1]) %in% headers){
      #some of the article text has "LOCATION:", especially police blotter transcripts, this is to make sure only the first instance of location is used.
      if (article_df[row,tolower(detail[1])] == ''){
        #for multiple authors store authors as list so that they can be referenced separately
        if (tolower(detail[1]) == 'author'){
          article_df[row,tolower(detail[1])] <- list(str_trim(str_split(detail[2],',')))
        } else if (tolower(detail[1]) == 'published'){
          date <- str_replace_all(str_replace_all(detail[2],'  ',' '),',','')
          article_df[row,'published'] <- date
        }
        article_df[row,tolower(detail[1])] <- str_trim(detail[2])
      } else {
        #concatenate body text
        article_df[row,'text'] <- paste(article_df[row,'text'],article_text[[1]][i], sep='\n')
      }
    } else {
      #concatenate body text
      article_df[row,'text'] <- paste(article_df[row,'text'],article_text[[1]][i], sep='\n')
    }
  } 
}

#convert the published dates to dates
article_df$published <- as.Date(parse_date_time(article_df$published,c('dmy','mdy','ymd')))

```
And we're done with the news article data!

## 2.2. GAStech employee relationships

## 2.3. Email headers

# 3. Solutions (Approach & Answers)

Using the prepared data, we now answer the questions with the help of some meaningful visualisations.

## 3.1. Question 1
_Characterize the news data sources provided. Which are primary sources and which are derivative sources? What are the relationships between the primary and derivative sources? Please limit your answer to 8 images and 300 words._

### 3.1.1. Solution Approach and Data Wrangling

There are two ways to detect derivative sources:

1. presence of other news source name in the text (e.g. quoting or crediting another news source)
2. same title and author as another article (e.g. reprinting or republishing a previous article from another news source)

**STEP 1:** Identify presence of other news source name

For the first approach, we will establish a listing of all news sources, and then check each article text for the presence of other news sources. We will use the detects to generate an adjacency matrix to visualise the links between articles. The relationship will be defined as follows:

1. The primary source will be the news source quoted
2. The derivative source is the article doing the quoting
3. The relationship is defined as "Quoting"

```{r}
news_sources <- c(unique(article_df$source))

#append one column for each news source to article df to establish an adjacency matrix
article_df[news_sources] <- NA

#mark TRUE whenever mentions of other news sources are detected
for (row in 1:nrow(article_df)){
  for (news_source in news_sources){
    if (article_df[row,'source'] != news_source){
      article_df[row,news_source] <- str_detect(article_df[row,'text'], news_source)
    }
    else{article_df[row,news_source] <- FALSE}
  }
}

#convert the adjacency matrix into a list of edges (primary doc_id, primary source, derivative doc_id, derivative source, edge type)
```

**STEP 2:** Identify articles with same title and author

First we compile a list of unique title-author combinations and extract the earliest publication of each combination. This list will be the basis for comparison against all the articles. Any articles published after the earliest publication is necessarily a reprint of the primary source. 

```{r, layout="l-body-outset"}
#establish a list of unique article title/author combinations and record the earliest publish date and the source

article_df_grouped <-  article_df %>%
  group_by(title,author) %>%
  arrange(published, by_group = TRUE) %>%
  summarise(first_doc_id = first(doc_id), 
            published = first(published), 
            news_source = first(source),
            text = first(text),
            #the below details are for further analysis
            count = n(), #count the number of times the title-author combo been published
            all_source = list(unique(source)), #list the number of news sources that have used this article
            all_doc = list(doc_id)) #list all the documents that share this article-author combination

datatable(article_df_grouped[,c(1:5,7:9)],
          class = 'cell-border stripe',
          caption = 'TABLE 1. List of unique article title-author combinations with number of repeats and sources that have published',
          rownames = FALSE,
          colnames = c("Unique title",
                       "Unique author",
                       "First Document ID",
                       "First published date",
                       "First published news source",
                       "Repeat count",
                       "All sources that have published this article",
                       "All articles with this title-author combination"))
```
One quick observation that we can make is that there are several instances where articles share titles (i.e. exact match) with one combination with an author's name indicated but another combination without an author's name. This indicates that there might be situations either where one source is plagarising another or authors with one publication are re-using their work with another publication without using their bylines.

To further investigate this we shall extract the text of all articles which share the same title for comparison. We should note that if there is only one news source that has used this title (even if there are multiple articles), then this article could be a topic header for a developing story, with periodic updates being provided. In such a case, we ignore it as it does not show a primary-derivative source relationship.

```{r, layout="l-body-outset", fig.width = 20}
#filter the article data to just those with identical titles, we will use this repeats table to extract the relevant article texts

article_df_repeats <- article_df %>%
  group_by(title) %>%
  summarise(count_articles = n(),
            num_unique_sources = length(list(unique(source))[[1]]), #count the number of news sources that have used this article title
            all_docs = list(doc_id) #list all the documents that share this article-author combination
            ) %>%
  filter(num_unique_sources > 1)

coladd <- ncol(article_df_repeats)

article_df_repeats[(coladd+1):(coladd+max(article_df_repeats$num_unique_sources))] <- ''

for (i in 1:nrow(article_df_repeats)){
  all_doc <- article_df_repeats$all_docs[i]
  for (j in 1:length(all_doc[[1]])){
    article_df_repeats[i,coladd+j] <- paste('DOC_ID: ',
                                            filter(article_df,article_df$doc_id == all_doc[[1]][j])['doc_id'][[1]],
                                            '\n',
                                            #source
                                            'SOURCE: ',
                                            filter(article_df,article_df$doc_id == all_doc[[1]][j])['source'][[1]],
                                            '\n',
                                            #author
                                            'AUTHOR: ',
                                            filter(article_df,article_df$doc_id == all_doc[[1]][j])['author'][[1]],
                                            '\n',
                                            #published date
                                            'PUBLISHED: ',
                                            format(filter(article_df,article_df$doc_id == all_doc[[1]][j])['published'][[1]],'%d-%m-%Y'),
                                            '\n',
                                            #location
                                            'LOCATION: ',
                                            filter(article_df,article_df$doc_id == all_doc[[1]][j])['location'][[1]],
                                            '\n',
                                            '\n',
                                            #text
                                            filter(article_df,article_df$doc_id == all_doc[[1]][j])['text'][[1]],
                                            '\n'
                                            )
  }
}

datatable(article_df_repeats[,c(1,5:10)], 
          class = 'cell-border stripe',
          caption = 'TABLE 2. Articles with identical titles for inspection',
          options = list(pageLength = 1,
                         height = 450,
                         width = 800),
          rownames = FALSE,
          colnames = c("Unique title",
                       "First article",
                       "Second article",
                       "Third article",
                       "Fourth article",
                       "Fifth article",
                       "Sixth article")) %>%
    formatStyle(1:5, 'vertical-align'='top') %>% 
    formatStyle(1:5, 'text-align' = 'left') 
```

```{r,eval = F, echo=F}
#export data for manual cleaning
write.csv(article_df_repeats[,c(1,5:10)],"article_compare.csv")
```

Briefly, from comparing some of the text in the above table, it appears that Petrus Gerhard is recycling articles that he writes for _Homeland Illumination_ for _All News Today_ (simply shortening the article and changing one or two words for _All News Today_), and often on the same day. Marcella Trapani and Eva Thayer are doing similar at _International News_ while officially writing for _Kronos Star_. There are many other cases, indicating that this "Shadow Author" phenomenon is probably much more widespread than previously expected. This warrants deeper investigation!!

To detect "Shadow Author" relationships, we will borrow a page from plagarism checker algorithms. We will use a simple substring matching approach to carry out this analysis. Simply put the method involves the following:

1. **Breakdown each document into a series of n-grams.** n should be a medium length, ~5 to 10 words. Too long, and it won't capture situations where authors change one or two words. Too short, and we would miss word patterns. For this case, we choose n = 6.
2. **Calculate a similarity score**, where 1 indicates that the entirety of document A is found in document B. The score is given by:
$$
similarity (\text{doc A to doc B}) = \frac{\text{no. of n-grams in doc A found in doc B}}{\text{total number of n-grams in doc A}}
$$
3. Noting that the score is directional (i.e. similarity of A to B may be 1, but if B is a longer document then similarity of B to A will be < 1), we should designate the shorter document (higher similarity score) as the derivative source and the longer document (lower similarity score) as the primary. Not all forms of "Shadow Author" relationships will be so neat. From our manual review of the articles in the above sections, it is clear that some shadow authors "mix and match" paragraphs around. For simplicity, we will define a "Shadow Author" relationship based on the following:
    + **Links between documents are defined as a similarity score of >0.1.** This allows for some coincidental overlaps in n-grams.
    + **One of the similarity scores between two articles is >0.5** (i.e. more than half of the n-grams in doc A can be found in doc B) indicates that one of the articles might have been "shadow authored".
    + **Document with the higher score will be designated as the derivative.**
    + **Document with the lower score will be designated as the primary.**
    + Where multiple documents are linked (similarity score >0.1), the **document with the lowest average similarity score will be designated as the primary source**, and all others will be designated as derivative.

```{r}
ngram_fp <- article_df[,c('doc_id','text')] %>%
  unnest_tokens(n-gram,text, token = "ngrams", n = 6)

ngram_fp$count = 1

#get a list of doc lengths (i.e. num of n-grams in the doc), we will use this to normalise similarity scores later
doc_length <- ngram_fp %>%
  group_by(doc_id) %>%
  summarise(doc_id = first(doc_id),
            doc_length = n())

#create 'n-gram'-document matrix
ndm <-ngram_fp %>%
  cast_tdm(n-gram,doc_id,count)

fp_similarity_mat <- crossprod_simple_triplet_matrix(ndm)/col_sums(ndm)
```






### 3.1.2. Answer


## 3.2. QUESTION 2
_Characterize any biases you identify in these news sources, with respect to their representation of specific people, places, and events. Give examples. Please limit your answer to 6 images and 500 words._

##3.2.1. Solution Approach and Data Wrangling

Visualising bias will require more in depth analysis of the article texts. We will used frequency-based analysis to characterise the articles.

```{r}
#define key words


```

Firstly, we will convert our corpus of articles into a document-term matrix, using [text frequency - inverse document frequency](https://www.tidytextmining.com/tfidf.html) (TF-IDF) to fill in the values. TF-IDF is used because it supresses words that appear commonly across all documents through the inverse document frequency term. This eliminates the need to specify stopwords to remove from the corpus, which is tedious and might not be too accurate as some stopwords also depend on the unique characteristics of each corpus. We will also lemmatize the words using the [textstem](https://rdrr.io/cran/textstem/) package to better capture the meaning of each document by converting various forms of words to their root word (e.g. 'running', 'ran', and 'run' will be reduced to 'run'). Another approach is stemming, where t   he ends of words are truncated based on heuristics to remove derivational and inflectional affixes (e.g. -s, -ed, -es, -ing, -tion). Past research ([di Nanzio, Vezzani, 2018](http://ceur-ws.org/Vol-2253/paper45.pdf)) has shown that lemmatization and stemming are comparable in terms of performance. We will go with lemmatization for this project because the output are base words, which are more understandable.

```{r}
dtm <- article_df[,c('doc_id','text')] %>%
  unnest_tokens(word,text) 

#lemmatize words
dtm$word <- lemmatize_words(dtm$word)

dtm <- dtm %>%
  count(doc_id, word, sort=TRUE)

dtm <- dtm %>%
  bind_tf_idf(word,doc_id, n)

tdm <-dtm %>%
  cast_tdm(word,doc_id,tf_idf)

library(slam)
cosine_dist_mat <- crossprod_simple_triplet_matrix(tdm)/(sqrt(col_sums(tdm^2) %*% t(col_sums(tdm^2))))

```
### 3.2.2. Answer


## 3.3. QUESTION 3 
_Given the data sources provided, use visual analytics to identify potential official and unofficial relationships among GASTech, POK, the APA, and Government. Include both personal relationships and shared goals and objectives. Provide evidence for these relationships. Please limit your answer to 6 images and 400 words._

### 3.3.1. Solution Approach and Data Wrangling

### 3.3.2. Answer

# References



